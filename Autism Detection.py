# -*- coding: utf-8 -*-
"""Video_Classification_03.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1H_vjBjea2YOXuJNbUgVjKnbroVAMXoJ0

**LSTM**
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from keras.models import Sequential
from keras.layers import Dense, LSTM

# Load the dataset into a pandas DataFrame
df = pd.read_csv('merged.csv')

print(df.columns)

# df.drop('Class/ASD', axis=1, inplace=True)

# Drop the result column as it contains the label we're trying to predict
#df.drop('Class/ASD Traits ', axis=1, inplace=True)

df = pd.get_dummies(df, columns=['age','gender', 'ethnicity','jundice','austim', 'result','Class/ASD'])

# Split the dataset into training and testing sets // 80% for training and 20% for testing
X_train, X_test, y_train, y_test = train_test_split(df.iloc[:, :-1], df.iloc[:, -1], test_size=0.2, random_state=42)

print(X_train.shape)  # should be (n_samples, n_features)
print(X_test.shape)   # should be (n_samples, n_features)

# Scale the training and testing sets
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

# Reshape the training and testing sets for LSTM input
X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))
X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))

# Build the LSTM model
model = Sequential()
model.add(LSTM(64, input_shape=(X_train.shape[1], 1)))
model.add(Dense(1, activation='sigmoid'))
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

# Train the LSTM model
model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test))

print(y_train)

feature_extractor_model = Sequential()
for layer in model.layers[:-1]:
    feature_extractor_model.add(layer)

# Load the new data from a CSV file
new_data = pd.read_csv('merged.csv')  # Replace 'your_new_data.csv' with the actual filename

# Drop the result column as it contains the label we're trying to predict
#new_data.drop('Class/ASD', axis=1, inplace=True)

# df = pd.get_dummies(df, columns=['age','gender', 'ethnicity','jundice','austim', 'result','Class/ASD'])

# Convert the categorical variables into dummy variables
new_data = pd.get_dummies(new_data, columns=['age','gender', 'ethnicity','jundice','austim', 'result','Class/ASD'])

# Preprocess the new data
X_new = new_data.iloc[:, :-1].values
X_new_normalized = sc.transform(X_new) # Scaling

print(X_new_normalized.shape)

# # This Step is important
# sequence_length = 34   # read more about these two varibles
# input_dim = 1
# #X_new_reshaped = X_new_normalized.reshape(X_new_normalized, (X_new_normalized.shape[0], X_new_normalized.shape[1], 1))
# X_new_reshaped = X_new_normalized.reshape((-1, sequence_length, input_dim))

features = feature_extractor_model.predict(X_new_normalized)

# Evaluate the LSTM model
score = model.evaluate(X_test, y_test)
print('Test loss:', score[0])
print('Test accuracy:', score[1])

model.summary()

print(features.shape)
print(type(features))
print(features.ndim)



"""To convert a 2D array features into a vector, you can use the flatten() method or the ravel() function in NumPy. Both methods perform the same task of flattening the array into a 1D vector."""

import numpy as np

# Assuming features is a 2D array with shape (1, 64)
features = features.flatten()  # or vector = features.ravel()

# splitting features in test and train
from sklearn.model_selection import train_test_split
train_feature_1, test_feature_1 = train_test_split(features, test_size=0.2, random_state=42)

"""End of LSTM

Start of Dense Net
"""

from google.colab import drive
drive.mount('/content/drive')

input_folder = '/content/drive/My Drive/ProjectThesis/ASD'

"""**Directory**"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import os

dataset_path = os.listdir('/content/drive/My Drive/ProjectThesis/ASD/train')

label_types = os.listdir('/content/drive/My Drive/ProjectThesis/ASD/train')
print (label_types)

"""**Preparing Training Data**"""

rooms = []

for item in dataset_path:
 # Get all the file names
 all_rooms = os.listdir('/content/drive/My Drive/ProjectThesis/ASD/train' + '/' +item)

 # Add them to the list
 for room in all_rooms:
    rooms.append((item, str('/content/drive/My Drive/ProjectThesis/ASD/train' + '/' +item) + '/' + room))

# Build a dataframe
train_df = pd.DataFrame(data=rooms, columns=['tag', 'video_name'])
print(train_df.head())
print(train_df.tail())

df = train_df.loc[:,['video_name','tag']]
df
df.to_csv('train.csv')

"""**Preparing Test Data**"""

dataset_path = os.listdir('/content/drive/My Drive/ProjectThesis/ASD/test')
print(dataset_path)

room_types = os.listdir('/content/drive/My Drive/ProjectThesis/ASD/test')
print("Types of activities found: ", len(dataset_path))

rooms = []

for item in dataset_path:
 # Get all the file names
 all_rooms = os.listdir('/content/drive/My Drive/ProjectThesis/ASD/test' + '/' +item)

 # Add them to the list
 for room in all_rooms:
    rooms.append((item, str('/content/drive/My Drive/ProjectThesis/ASD/test' + '/' +item) + '/' + room))

# Build a dataframe
test_df = pd.DataFrame(data=rooms, columns=['tag', 'video_name'])
print(test_df.head())
print(test_df.tail())

df = test_df.loc[:,['video_name','tag']]
df
df.to_csv('test.csv')

!pip install git+https://github.com/tensorflow/docs

from tensorflow_docs.vis import embed
from tensorflow import keras
from imutils import paths

import matplotlib.pyplot as plt
import tensorflow as tf
import pandas as pd
import numpy as np
import imageio
import cv2
import os

gpus = tf.config.experimental.list_physical_devices('GPU')
if gpus:
  try:
    tf.config.experimental.set_virtual_device_configuration(
        gpus[0],[tf.config.experimental.VirtualDeviceConfiguration(memory_limit=5120)])
  except RuntimeError as e:
    print(e)

"""**Data preparation**"""

train_df = pd.read_csv("train.csv")
test_df = pd.read_csv("test.csv")

print(f"Total videos for training: {len(train_df)}")
print(f"Total videos for testing: {len(test_df)}")


train_df.sample(10)

"""**Feed the videos to a network:**"""

# The following two methods are taken from this tutorial:
# https://www.tensorflow.org/hub/tutorials/action_recognition_with_tf_hub
IMG_SIZE = 224


def crop_center_square(frame):
    y, x = frame.shape[0:2]
    min_dim = min(y, x)
    start_x = (x // 2) - (min_dim // 2)
    start_y = (y // 2) - (min_dim // 2)
    return frame[start_y : start_y + min_dim, start_x : start_x + min_dim]


def load_video(path, max_frames=0, resize=(IMG_SIZE, IMG_SIZE)):
    cap = cv2.VideoCapture(path)
    frames = []
    try:
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            frame = crop_center_square(frame)
            frame = cv2.resize(frame, resize)
            frame = frame[:, :, [2, 1, 0]]
            frames.append(frame)

            if len(frames) == max_frames:
                break
    finally:
        cap.release()
    return np.array(frames)

"""**Feature Extraction**"""

def build_feature_extractor():
    feature_extractor = keras.applications.DenseNet121(
        weights="imagenet",
        include_top=False,
        pooling="avg",
        input_shape=(IMG_SIZE, IMG_SIZE, 3),
    )
    preprocess_input = keras.applications.inception_v3.preprocess_input  ############ Inception is used here, why.

    inputs = keras.Input((IMG_SIZE, IMG_SIZE, 3))
    preprocessed = preprocess_input(inputs)

    outputs = feature_extractor(preprocessed)

    return keras.Model(inputs, outputs, name="feature_extractor")


feature_extractor = build_feature_extractor()

feature_extractor.summary()

#print(outputs) #######################

"""**Label Encoding**
StringLookup layer encode the class labels as integers.
"""

label_processor = keras.layers.StringLookup(num_oov_indices=0, vocabulary=np.unique(train_df["tag"]))
print(label_processor.get_vocabulary())

labels = train_df["tag"].values
labels = label_processor(labels[..., None]).numpy()
labels

"""Finally, we can put all the pieces together to create our data processing utility."""

#Define hyperparameters

IMG_SIZE = 224
BATCH_SIZE = 64
EPOCHS = 20   ########################################

MAX_SEQ_LENGTH = 20
NUM_FEATURES = 1024 # I changed it from 2048 to 1024 for DenseNet121 in feature extraction.

def prepare_all_videos(df, root_dir):
    num_samples = len(df)
    video_paths = df["video_name"].values.tolist()
    labels = df["tag"].values
    labels = label_processor(labels[..., None]).numpy()

    frame_masks = np.zeros(shape=(num_samples, MAX_SEQ_LENGTH), dtype="bool")
    frame_features = np.zeros(shape=(num_samples, MAX_SEQ_LENGTH, NUM_FEATURES), dtype="float32")

    for idx, path in enumerate(video_paths):
        frames = load_video(os.path.join(root_dir, path))
        frames = frames[None, ...]

        temp_frame_mask = np.zeros(shape=(1, MAX_SEQ_LENGTH,), dtype="bool")
        temp_frame_features = np.zeros(shape=(1, MAX_SEQ_LENGTH, NUM_FEATURES), dtype="float32")

        for i, batch in enumerate(frames):
            video_length = batch.shape[0]
            length = min(MAX_SEQ_LENGTH, video_length)
            for j in range(length):
                temp_frame_features[i, j, :] = feature_extractor.predict(batch[None, j, :])
            temp_frame_mask[i, :length] = 1

        frame_features[idx,] = temp_frame_features.squeeze()
        frame_masks[idx,] = temp_frame_mask.squeeze()

    # Reshape frame_features to have shape (num_samples * MAX_SEQ_LENGTH, NUM_FEATURES)
    frame_features = frame_features.reshape(-1, NUM_FEATURES)
   # frame_masks = frame_masks.reshape(-1, NUM_FEATURES)

    return (frame_features, frame_masks), labels

train_data, train_labels = prepare_all_videos(train_df, "train")
test_data, test_labels = prepare_all_videos(test_df, "test")

# Print the updated shapes
print(f"Frame features in train set: {train_data[0].shape}")
print(f"Frame masks in train set: {train_data[1].shape}")

# Print the updated train_labels shape
print(f"train_labels in train set: {train_labels.shape}")

"""Concatenating Features from both Models"""

print(features.shape)
print(type(features))

print(features.ndim)
print(features.size)

#features.reshape(-1)

print(type(features))

#

print(train_data[0].shape)
print(type(train_data[0]))

print(train_data[0].ndim)

#combined_features = np.concatenate((train_data[0], features), axis=0)

print(train_data)

# create an array of size 67456
  #arr = np.random.rand(features.size)

  # find a shape with 20 rows that has the same number of elements as the original array
  #cols = arr.size // 20
  #new_shape = (19, 1024)

  # reshape the array to the new shape
  #features = arr.reshape(new_shape)

print(train_feature_1.shape)
print(test_feature_1.shape)

import math
temp = train_feature_1.size/MAX_SEQ_LENGTH
print(train_feature_1.size)
print(temp)
temp = temp/NUM_FEATURES
print(temp)
temp = math.ceil(temp)
print(temp)
print(temp*MAX_SEQ_LENGTH*NUM_FEATURES)

import math
temp2 = test_feature_1.size/MAX_SEQ_LENGTH
temp2 = temp2/NUM_FEATURES
temp2 = math.ceil(temp2)
print(temp2)

temp3 = MAX_SEQ_LENGTH*NUM_FEATURES*temp
print(temp3)
print(train_feature_1.size)

train_feature_1 = np.pad(train_feature_1, (0, temp3-train_feature_1.size), mode='constant', constant_values=0)

temp4 = MAX_SEQ_LENGTH*NUM_FEATURES*temp2

test_feature_1 = np.pad(test_feature_1, (0, temp4-test_feature_1.size), mode='constant', constant_values=0)

train_feature_1 = train_feature_1.reshape(-1,MAX_SEQ_LENGTH, NUM_FEATURES)

test_feature_1 = test_feature_1.reshape(-1,MAX_SEQ_LENGTH, NUM_FEATURES)

#features = features.reshape(-1,MAX_SEQ_LENGTH, NUM_FEATURES)

# Reshaping Train data
train_features = train_data[0].reshape(-1, MAX_SEQ_LENGTH, NUM_FEATURES)
print(train_features.shape)
print(type(train_features))
print(train_features.ndim)
print(train_features.size)

# Reshaping Test data
test_features = test_data[0].reshape(-1, MAX_SEQ_LENGTH, NUM_FEATURES)
print(test_features.shape)
print(type(test_features))
print(test_features.ndim)
print(test_features.size)

# concatenate the two arrays along the first axis
#result = np.concatenate((array2d_reshaped, array3d), axis=0)

#train_features = np.array(train_data)
#print(train_features.shape)

train_features = np.concatenate((train_features, train_feature_1), axis=0)
test_features = np.concatenate((test_features, test_feature_1), axis=0)

print(type(y_train))
print(type(train_labels))

#y_train = y_train.reshape(train_labels.shape)
#train_labels = np.concatenate((train_labels,y_train), axis=0)

# It is required.
# print(combined_train_features.shape)
# print(train_labels.shape)

"""Given"""

from tensorflow import keras

# Define the RNN model
def build_rnn_model():
    model = keras.models.Sequential([
        keras.layers.Masking(mask_value=0.0, input_shape=(MAX_SEQ_LENGTH, NUM_FEATURES)),
        keras.layers.GRU(16),
        keras.layers.Dropout(0.4),
        keras.layers.Dense(8, activation='relu'),
        keras.layers.Dense(len(label_processor.get_vocabulary()), activation='softmax')
    ])
    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
    return model

# Build and train the RNN model
rnn_model = build_rnn_model()
rnn_model.summary()  # Print the model summary

# Reshape the training and testing data to match the RNN input shape
train_features = train_data[0].reshape(-1, MAX_SEQ_LENGTH, NUM_FEATURES)
test_features = test_data[0].reshape(-1, MAX_SEQ_LENGTH, NUM_FEATURES)

# Train the model
history = rnn_model.fit(train_features, train_labels, validation_split=0.3, epochs=EPOCHS)

# Evaluate the model on the testing data
_, accuracy = rnn_model.evaluate(test_features, test_labels)
print(f"Test accuracy: {round(accuracy * 100, 2)}%")

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']

loss = history.history['loss']
val_loss = history.history['val_loss']

plt.figure(figsize=(8, 8))
plt.subplot(2, 1, 1)
plt.plot(acc, label='Training Accuracy')
plt.plot(val_acc, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.ylabel('Accuracy')
plt.ylim([min(plt.ylim()), 1])
plt.title('Training and Validation Accuracy')

plt.subplot(2, 1, 2)
plt.plot(loss, label='Training Loss')
plt.plot(val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.ylabel('Loss')
plt.ylim([0, 1.0])
plt.title('Training and Validation Loss')
plt.xlabel('epoch')
plt.show()